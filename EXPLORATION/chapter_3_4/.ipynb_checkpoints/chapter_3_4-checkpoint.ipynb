{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:blue; font-size:150%\"> \n",
    "<b>train.csvë¥¼ í™œìš©í•´ì„œ ë°ì´í„°ë¥¼ ëœ¯ì–´ë³´ê³  ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ í›„, test.csv íŒŒì¼ì˜ ë°ì´í„°ì— ëŒ€í•´ priceë¥¼ ì˜ˆì¸¡í•´ì„œ sample_submission.csvì˜ í˜•ì‹ì— ë§ëŠ” í˜•íƒœë¡œ ìºê¸€ì— ì œì¶œ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‹œê°í™” ê·¸ë˜í”„ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë„ë¡ í•˜ê¸°ìœ„í•´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ê°€ì ¸ì™€ì„œ Read í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.getenv(\"HOME\") + \"/aiffel/kaggle_kakr_housing/data/train.csv\"\n",
    "sub_data_path = os.getenv(\"HOME\") + \"/aiffel/kaggle_kakr_housing/data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(train_data_path)\n",
    "sub = pd.read_csv(sub_data_path)\n",
    "print(f'train data dim : {data.shape}')\n",
    "print(f'sub data dim : {sub.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = data['price']\n",
    "del data['price']\n",
    "\n",
    "print(data.columns)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(data)\n",
    "data = pd.concat((data, sub), axis=0)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.matrix(data)  #missing no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. id ì»¬ëŸ¼ì´ ê²°ì¸¡ì¹˜ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "null_check = pd.isnull(data['id'])\n",
    "print(null_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ê²°ì¸¡ì¹˜ì¸ ë°ì´í„°ë§Œ ë½‘ì•„ëƒ…ë‹ˆë‹¤.\n",
    "null_data = data.loc[null_check, 'id']  #[row index, column index]\n",
    "null_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ê²°ì¸¡ì¹˜ì¸ ë°ì´í„°ì˜ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤.\n",
    "print(f'id: {len(null_data.values)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    print('{} : {}'.format(c, len(data.loc[pd.isnull(data[c]), c].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trainê³¼ subë¥¼ í•©ì¹œ í›„, id columì„ ì§€ìš°ê¸° ì „ subì˜ idë¥¼ ë”°ë¡œ ë³´ê´€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = data['id'][train_len:]\n",
    "del data['id']\n",
    "\n",
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['date'].apply(lambda x : str(x[:6]))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(9, 2, figsize=(12, 50))   # ê°€ë¡œìŠ¤í¬ë¡¤ ë•Œë¬¸ì— ê·¸ë˜í”„ í™•ì¸ì´ ë¶ˆí¸í•˜ë‹¤ë©´ figsizeì˜ xê°’ì„ ì¡°ì ˆí•´ ë³´ì„¸ìš”. \n",
    "\n",
    "# id ë³€ìˆ˜(count==0ì¸ ê²½ìš°)ëŠ” ì œì™¸í•˜ê³  ë¶„í¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "count = 1\n",
    "columns = data.columns\n",
    "for row in range(9):\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data=data[columns[count]], ax=ax[row][col])  # A kernel density estimate (KDE) plot (data=None, .... ax, )\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        if count == 19 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•œ ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ ë¶„í¬ì˜ ê²½ìš°ì—ëŠ” ë¡œê·¸ ë³€í™˜(log-scaling)ì„ í†µí•´ ë°ì´í„° ë¶„í¬ë¥¼ ì •ê·œë¶„í¬ì— ê°€ê¹ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_lot15', 'sqft_living15']\n",
    "\n",
    "for c in skew_columns:\n",
    "    data[c] = np.log1p(data[c].values)  \n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns = data[skew_columns].columns\n",
    "\n",
    "count = 0\n",
    "fig, ax = plt.subplots(4, 2, figsize=(12, 25))   # ê°€ë¡œìŠ¤í¬ë¡¤ ë•Œë¬¸ì— ê·¸ë˜í”„ í™•ì¸ì´ ë¶ˆí¸í•˜ë‹¤ë©´ figsizeì˜ xê°’ì„ ì¡°ì ˆí•´ ë³´ì„¸ìš”. \n",
    "\n",
    "for row in range(4):\n",
    "    for col in range(2):\n",
    "        if count == 7 :\n",
    "            break\n",
    "        sns.kdeplot(data=data[columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why log?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(0, 10, 500)  # 0~10ì‚¬ì´ 500ê°œì˜ ìˆ«ìë¥¼ ìˆœì„œëŒ€ë¡œ ì±„ìš°ëŠ” í•¨ìˆ˜\n",
    "yy = np.log(xx)\n",
    "\n",
    "plt.hlines(0, 0, 10)  # horizontal line (y, xmin, xmax,)\n",
    "plt.vlines(0, -5, 5)  # vertical line(x, ymin, ymax, )\n",
    "plt.plot(xx, yy, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price ê°’ log ë¹„êµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 0ê³¼ 1000000 ì‚¬ì´ì— ëŒ€ë¶€ë¶„ì˜ ê°’ë“¤ì´ ëª°ë ¤ìˆê³   ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,3)) \n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.kdeplot(y)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "y_log_transformation = np.log1p(y)\n",
    "sns.kdeplot(y_log_transformation)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = data.iloc[train_len:, :]  # Test data\n",
    "x = data.iloc[:train_len, :]   # Train data\n",
    "\n",
    "print(x.shape)\n",
    "print(sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Introduction to Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Blending(ì§‘ê°’ì„ ë¶„ë¥˜ì¤‘ì´ë¯€ë¡œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor(random_state=2019)\n",
    "xgboost = xgb.XGBRegressor(random_state=2019)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=2019)\n",
    "\n",
    "models = [{'model':gboost, 'name':'GradientBoosting'}, {'model':xgboost, 'name':'XGBoost'},\n",
    "          {'model':lightgbm, 'name':'LightGBM'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation : í•™ìŠµìš©/ í‰ê°€ìš© ë°ì´í„° ì„¸íŠ¸ë¥¼ ë‚˜ëˆ„ëŠ” ë°©ë²•ë¡  ì¤‘ì˜ í•˜ë‚˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_score(models):\n",
    "    kfold = KFold(n_splits=5).get_n_splits(x.values)\n",
    "    for m in models:\n",
    "        CV_score = np.mean(cross_val_score(m['model'], X=x.values, y=y, cv=kfold))  #y = price\n",
    "        print(f\"Model: {m['name']}, CV score:{CV_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_scoreëŠ” R**2 ê°’ì„ return í•¨\n",
    "### R**2 :   ê°’ì€ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ëª¨ë¸ì´ ì˜ í•™ìŠµë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_cv_score(models)  # cv : Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking - k-c=Cross Folding ê¸°ë²• ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AveragingBlending(models, x, y, sub_x):\n",
    "    for m in models : \n",
    "        m['model'].fit(x.values, y) # Model Training\n",
    "    \n",
    "    predictions = np.column_stack([\n",
    "        m['model'].predict(sub_x.values) for m in models\n",
    "    ])\n",
    "    return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = AveragingBlending(models, x, y, sub)\n",
    "print(len(y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'id' : sub_id, \n",
    "    'price' : y_pred\n",
    "})\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:green; font-size:150%\"> \n",
    "<b>Q.ì•ì—ì„œ ë°°ì› ë˜ joinê³¼ to_csv ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ 'submission.csv' íŒŒì¼ë¡œ ì €ì¥í•´ ë³´ì„¸ìš”.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission_path =  join(data_dir, 'submission.csv') # [[YOUR CODE]]\n",
    "\n",
    "# [[YOUR CODE]]\n",
    "result.to_csv(my_submission_path, index = False)\n",
    "print(my_submission_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìµœì ì˜ ëª¨ë¸ì„ ì°¾ì•„ì„œ, í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color: blue; font-size:110%\"> \n",
    "<b>Train data ì „ì²˜ë¦¬í•˜ê¸°</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "test_data_path = join(data_dir, 'test.csv') \n",
    "\n",
    "train = pd.read_csv(train_data_path)\n",
    "test = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['date'] = train['date'].apply(lambda i: i[:6]).astype(int)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['price']\n",
    "del train['price']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['id']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color: blue; font-size:110%\"> \n",
    "<b>Test data ì „ì²˜ë¦¬í•˜ê¸°</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:green; font-size:150%\"> \n",
    "<b>Q. train ë°ì´í„°ì™€ ë§ˆì°¬ê°€ì§€ë¡œ test ë°ì´í„°ë„ ì „ì²˜ë¦¬í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ ë³´ì„¸ìš”.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [[YOUR CODE]]\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['date'] = test['date'].apply(lambda i: i[:6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = test[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del test[\"id\"]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head()\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:green; font-size:150%\"> \n",
    "<b>Q. Tseabornì˜ `kdeplot`ì„ í™œìš©í•´ `y`ì˜ ë¶„í¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = np.log1p(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color: blue; font-size:110%\"> \n",
    "<b>RMSE ê³„ì‚°</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_stateëŠ” ëª¨ë¸ì´ˆê¸°í™”ë‚˜ ë°ì´í„°ì…‹ êµ¬ì„±ì— ì‚¬ìš©ë˜ëŠ” ëœë¤ ì‹œë“œê°’ì…ë‹ˆë‹¤. \n",
    "#random_state=None    # ì´ê²Œ ì´ˆê¸°ê°’ì…ë‹ˆë‹¤. ì•„ë¬´ê²ƒë„ ì§€ì •í•˜ì§€ ì•Šê³  Noneì„ ë„˜ê²¨ì£¼ë©´ ëª¨ë¸ ë‚´ë¶€ì—ì„œ ì„ì˜ë¡œ ì„ íƒí•©ë‹ˆë‹¤.  \n",
    "random_state=2020        # í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” ì´ë ‡ê²Œ ê³ ì •ê°’ì„ ì„¸íŒ…í•´ ë‘ê² ìŠµë‹ˆë‹¤. \n",
    "\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = XGBRegressor(random_state=random_state)\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest]\n",
    "\n",
    "print('ì–ğŸ’¢')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¤ìŒê³¼ ê°™ì´ forë¬¸ ì•ˆì—ì„œ ê° ëª¨ë¸ ë³„ë¡œ í•™ìŠµ ë° ì˜ˆì¸¡ì„ í•´ë³¼ ìˆ˜ ìˆì£ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AveragingBlending(models, x, y, sub_x):\n",
    "    for m in models : \n",
    "        m['model'].fit(x.values, y) # Model Training\n",
    "    \n",
    "    predictions = np.column_stack([\n",
    "        m['model'].predict(sub_x.values) for m in models\n",
    "    ])\n",
    "    return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "for model in models:\n",
    "    # ëª¨ë¸ ì´ë¦„ íšë“\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # train, test ë°ì´í„°ì…‹ ë¶„ë¦¬\n",
    "    # random_stateë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ì •í•˜ê³  trainê³¼ test ì…‹ì˜ ë¹„ìœ¨ì€ 8:2ë¡œ í•©ë‹ˆë‹¤.\n",
    "    # [[YOUR CODE]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            train, y, random_state=random_state,\n",
    "            test_size = 0.2)\n",
    "\n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    model.fit(X_train.values, y_train)\n",
    "    \n",
    "   # ì˜ˆì¸¡\n",
    "   # [[YOUR CODE]]\n",
    "    \n",
    "    predictions = model.predict(X_test.values)\n",
    "    \n",
    "     # ì˜ˆì¸¡ ê²°ê³¼ì˜ rmseê°’ ì €ì¥\n",
    "    df[model_name] = rmse(y_test, predictions)# [[YOUR CODE]]\n",
    "    \n",
    "    # data frameì— ì €ì¥\n",
    "    score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(models, train, y):\n",
    "    df = {}\n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        df[model_name] = rmse(y_test, y_pred)\n",
    "        score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "            \n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions.shape, test.shape, train.shape, y.shape, type(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_scores(models, train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter Tunning : Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(random_state=random_state)   #LightGBM : Ensemble Boosting ê¸°ë²•ì¤‘ í•˜ë‚˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
    "                        scoring='neg_mean_squared_error', \\\n",
    "                        cv=5, verbose=1, n_jobs=5)\n",
    "\n",
    "grid_model.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = grid_model.cv_results_['params']\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = grid_model.cv_results_['mean_test_score']\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(params)\n",
    "results['score'] = score\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results['RMSE'] = np.sqrt(-1 * results['score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = results.rename(columns={'RMSE': 'RMSLE'})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = results.sort_values('RMSLE')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "}\n",
    "\n",
    "model = LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
    "                        scoring='neg_mean_squared_error', \\\n",
    "                        cv=5, verbose=1, n_jobs=5)\n",
    "\n",
    "grid_model.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(max_depth=10, n_estimators=100, random_state=random_state)\n",
    "model.fit(train, y)\n",
    "prediction = model.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:green; font-size:150%\"> \n",
    "<b>Q.ì•ì—ì„œ ë¡œê·¸ ë³€í™˜ì„ í–ˆë˜ ê²ƒì„ ë‹¤ì‹œ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë˜ëŒë¦¬ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.expm1(prediction)# [[YOUR CODE]]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission['price'] = prediction\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, 'lgbm', '0.164399')\n",
    "submission.to_csv(submission_csv_path, index=False)\n",
    "print(submission_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(model, train, y, test, model_name, rmsle=None):\n",
    "    model.fit(train, y)\n",
    "    prediction = model.predict(test)\n",
    "    prediction = np.expm1(prediction)\n",
    "    data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "    submission_path = join(data_dir, 'sample_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    submission['price'] = prediction\n",
    "    submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, model_name, rmsle)\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    print('{} saved!'.format(submission_csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_submission(model, train, y, test, 'lgbm', rmsle='0.164399')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaderboard ì •ë³µí•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "}\n",
    "\n",
    "model = LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "    'learning_rate':[0.0001,0.001,0.1],\n",
    "  #   'boosting_type' : [\"gbdt\", 'dart'], \n",
    "     'num_leaves': [20],\n",
    "    'num_iterations':[200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
    "                        scoring='neg_mean_squared_error', \\\n",
    "                        cv=5, verbose=1, n_jobs=5)\n",
    "\n",
    "grid_model.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = grid_model.cv_results_['params']\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = grid_model.cv_results_['mean_test_score']\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(params)\n",
    "results['score'] = score\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results['RMSE'] = np.sqrt(-1 * results['score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = results.rename(columns={'RMSE': 'RMSLE'})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = results.sort_values('RMSLE')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(model, train, y, test, 'lgbm', rmsle='0.163302')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learningR = [0.1, 0.01, 0.001]\n",
    "np.array(learningR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for  lr in learningR:\n",
    "    learning_rate = lr\n",
    "    model = LGBMRegressor(max_depth=50, n_estimators=150, learning_rate =0.1000, random_state=random_state)\n",
    "    model.fit(train, y)\n",
    "    prediction = model.predict(test)\n",
    "    \n",
    "    result = pd.DataFrame[learning_rate]\n",
    "    result['prediction'] = prediction\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
